library(ggplot2)
library(dplyr)
# compare two methods
set.seed(1)
B_rep <- 500
# parameter in epsilon-greedy algorithm
eps <- 0.1
# distribution family
dist_fam <- c("gaussian")
# number of sample, dimension of covariate, number of active covariate
n <- 350
p <- 2
# initial sampling probability
initial_prob <- c(0.5, 0.5)
# specify the coefficient
coef_list <- list(
beta_1 <- numeric(p),
beta_2 <- numeric(p)
)
# significance level
sig_level <- 0.1
signal_level <- seq(0, 0.5, length.out = 5)
# method_list and construct the empty matrix
methods <- c("naive", "normalized_aw",
"normalized_cw",
"unnormalized_aw",
"unnormalized_cw")
# create empty array
result_mat_bootstrap <- array(
data = NA,
dim = c(B_rep, length(methods), length(signal_level)),
dimnames =  list(realization = 1:B_rep,
method = methods,
signal = signal_level)
)
for (signal in signal_level) {
true_mean <- c(0, signal)
# true mean vector
dist_params <- data.frame(
mu = true_mean,
sd = c(1, 2)
)
cumulative_realization <- 0
while (cumulative_realization < B_rep) {
# generate data
data <- data_generate_online(eps = eps, dist_fam = dist_fam, n = n, p = p, coef_list = coef_list, deciding_scheme = "IPW",
dist_params = dist_params, initial_prob = initial_prob, reg_type = reg_type,
hyperparams = hyperparams)
num_arm_second_batch <- length(unique(data$arm[which(data$batch_id == 2)]))
if(num_arm_second_batch == 1){
next
}
################################################################################
# naive estimator
IPW_pt <- IPW(data, first_batch = TRUE)
point_estimate <- IPW_pt$IPW_mean[1] - IPW_pt$IPW_mean[2]
sd_estimate <- sqrt(IPW_pt$IPW_variance[1] + IPW_pt$IPW_variance[2])
# compute normalized ci interval
ci_lower_naive <- point_estimate - qnorm(1 - sig_level / 2)*sd_estimate / sqrt(n / 2)
ci_upper_naive <- point_estimate - qnorm(sig_level / 2)*sd_estimate / sqrt(n / 2)
# store the intervals
ci_naive <- c(ci_lower_naive, ci_upper_naive)
################################################################################
# adaptive weighting
# weighted test statistic
IPW_pt <- weighted_IPW(data)
data_trans <- data
data_trans$reward <- data_trans$reward^2
IPW_sq <- weighted_IPW(data_trans)
variance_Y <- c(IPW_sq["point", 1] - IPW_pt["point", 1]^2,
IPW_sq["point", 2] - IPW_pt["point", 2]^2)
if(any(variance_Y <= 0)){
next
}
point_estimate <- IPW_pt["point", 1] - IPW_pt["point", 2]
var_estimate <- sqrt(IPW_pt["variance", 1] + IPW_pt["variance", 2])
# compute the bootstrap sample for normalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "normalized",
weighting = "aw")
# compute normalized ci interval
ci_lower_normalized_aw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2)*var_estimate
ci_upper_normalized_aw <- point_estimate - quantile(candidate_sample, sig_level / 2)*var_estimate
# store the intervals
ci_normalized_aw <- c(ci_lower_normalized_aw, ci_upper_normalized_aw)
# compute the bootstrap sample for unnormalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "unnormalized",
weighting = "aw")
# compute normalized ci interval
ci_lower_unnormalized_aw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2) / sqrt(n / 2)
ci_upper_unnormalized_aw <- point_estimate - quantile(candidate_sample, sig_level / 2) / sqrt(n / 2)
# store the intervals
ci_unnormalized_aw <- c(ci_lower_unnormalized_aw, ci_upper_unnormalized_aw)
################################################################################
# constant weighting
# unweighted test statistic
IPW_pt <- IPW_pt(data)
data_trans <- data
data_trans$reward <- data_trans$reward^2
IPW_sq <- weighted_IPW(data_trans)
variance_Y <- c(IPW_sq["point", 1] - IPW_pt["point", 1]^2,
IPW_sq["point", 2] - IPW_pt["point", 2]^2)
if(any(variance_Y <= 0)){
next
}
point_estimate <- IPW_pt["point", 1] - IPW_pt["point", 2]
var_estimate <- sqrt(IPW_pt["variance", 1] + IPW_pt["variance", 2])
# compute the bootstrap sample
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "normalized",
weighting = "cw")
# compute two types of confidence interval
ci_lower_normalized_cw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2)*var_estimate
ci_upper_normalized_cw <- point_estimate - quantile(candidate_sample, sig_level / 2)*var_estimate
# store the intervals
ci_normalized_cw <- c(ci_lower_normalized_cw, ci_upper_normalized_cw)
# compute the bootstrap sample for unnormalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "unnormalized",
weighting = "cw")
# compute normalized ci interval
ci_lower_unnormalized_cw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2) / sqrt(n*2)
ci_upper_unnormalized_cw <- point_estimate - quantile(candidate_sample, sig_level / 2) / sqrt(n*2)
# store the intervals
ci_unnormalized_cw <- c(ci_lower_unnormalized_cw, ci_upper_unnormalized_cw)
################################################################################
# store the rejection rate
result_mat_bootstrap[cumulative_realization + 1, "naive", as.character(signal)] <- dplyr::if_else(all(0 > ci_naive[1],
0 < ci_naive[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "normalized_aw", as.character(signal)] <- dplyr::if_else(all(0 > ci_normalized_aw[1],
0 < ci_normalized_aw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "normalized_cw", as.character(signal)] <- dplyr::if_else(all(0 > ci_normalized_cw[1],
0 < ci_normalized_cw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "unnormalized_aw", as.character(signal)] <- dplyr::if_else(all(0 > ci_unnormalized_aw[1],
0 < ci_unnormalized_aw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "unnormalized_cw", as.character(signal)] <- dplyr::if_else(all(0 > ci_unnormalized_cw[1],
0 < ci_unnormalized_cw[2]),
0, 1)
# print the result
print(apply(as.matrix(result_mat_bootstrap[1:(cumulative_realization + 1), , as.character(signal)]), 2, mean))
# add the loop iteration
cumulative_realization <- cumulative_realization + 1
print(cumulative_realization)
}
}
# create the results folder
results_dir <- "overview/results"
if (!dir.exists(results_dir)) {
dir.create(results_dir)
cat("Directory created:", results_dir, "\n")
} else {
cat("Directory already exists:", results_dir, "\n")
}
data_to_save <- as_tibble(as.table(result_mat_bootstrap)) |>
rename(rejection = n) |>
mutate(signal = as.numeric(signal))
# save the result
saveRDS(data_to_save, sprintf("%s/greedy_%d.rds", results_dir, eps*100))
# This is a file demonstrating the usage of the functions in AdaReg package
library(AdaReg)
library(ggplot2)
library(dplyr)
# compare two methods
set.seed(1)
B_rep <- 500
# parameter in epsilon-greedy algorithm
eps <- 0.2
# distribution family
dist_fam <- c("gaussian")
# number of sample, dimension of covariate, number of active covariate
n <- 350
p <- 2
# initial sampling probability
initial_prob <- c(0.5, 0.5)
# specify the coefficient
coef_list <- list(
beta_1 <- numeric(p),
beta_2 <- numeric(p)
)
# significance level
sig_level <- 0.1
signal_level <- seq(0, 0.5, length.out = 5)
# method_list and construct the empty matrix
methods <- c("naive", "normalized_aw",
"normalized_cw",
"unnormalized_aw",
"unnormalized_cw")
# create empty array
result_mat_bootstrap <- array(
data = NA,
dim = c(B_rep, length(methods), length(signal_level)),
dimnames =  list(realization = 1:B_rep,
method = methods,
signal = signal_level)
)
for (signal in signal_level) {
true_mean <- c(0, signal)
# true mean vector
dist_params <- data.frame(
mu = true_mean,
sd = c(1, 2)
)
cumulative_realization <- 0
while (cumulative_realization < B_rep) {
# generate data
data <- data_generate_online(eps = eps, dist_fam = dist_fam, n = n, p = p, coef_list = coef_list, deciding_scheme = "IPW",
dist_params = dist_params, initial_prob = initial_prob, reg_type = reg_type,
hyperparams = hyperparams)
num_arm_second_batch <- length(unique(data$arm[which(data$batch_id == 2)]))
if(num_arm_second_batch == 1){
next
}
################################################################################
# naive estimator
IPW_pt <- IPW(data, first_batch = TRUE)
point_estimate <- IPW_pt$IPW_mean[1] - IPW_pt$IPW_mean[2]
sd_estimate <- sqrt(IPW_pt$IPW_variance[1] + IPW_pt$IPW_variance[2])
# compute normalized ci interval
ci_lower_naive <- point_estimate - qnorm(1 - sig_level / 2)*sd_estimate / sqrt(n / 2)
ci_upper_naive <- point_estimate - qnorm(sig_level / 2)*sd_estimate / sqrt(n / 2)
# store the intervals
ci_naive <- c(ci_lower_naive, ci_upper_naive)
################################################################################
# adaptive weighting
# weighted test statistic
IPW_pt <- weighted_IPW(data)
data_trans <- data
data_trans$reward <- data_trans$reward^2
IPW_sq <- weighted_IPW(data_trans)
variance_Y <- c(IPW_sq["point", 1] - IPW_pt["point", 1]^2,
IPW_sq["point", 2] - IPW_pt["point", 2]^2)
if(any(variance_Y <= 0)){
next
}
point_estimate <- IPW_pt["point", 1] - IPW_pt["point", 2]
var_estimate <- sqrt(IPW_pt["variance", 1] + IPW_pt["variance", 2])
# compute the bootstrap sample for normalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "normalized",
weighting = "aw")
# compute normalized ci interval
ci_lower_normalized_aw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2)*var_estimate
ci_upper_normalized_aw <- point_estimate - quantile(candidate_sample, sig_level / 2)*var_estimate
# store the intervals
ci_normalized_aw <- c(ci_lower_normalized_aw, ci_upper_normalized_aw)
# compute the bootstrap sample for unnormalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "unnormalized",
weighting = "aw")
# compute normalized ci interval
ci_lower_unnormalized_aw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2) / sqrt(n / 2)
ci_upper_unnormalized_aw <- point_estimate - quantile(candidate_sample, sig_level / 2) / sqrt(n / 2)
# store the intervals
ci_unnormalized_aw <- c(ci_lower_unnormalized_aw, ci_upper_unnormalized_aw)
################################################################################
# constant weighting
# unweighted test statistic
IPW_pt <- IPW_pt(data)
data_trans <- data
data_trans$reward <- data_trans$reward^2
IPW_sq <- weighted_IPW(data_trans)
variance_Y <- c(IPW_sq["point", 1] - IPW_pt["point", 1]^2,
IPW_sq["point", 2] - IPW_pt["point", 2]^2)
if(any(variance_Y <= 0)){
next
}
point_estimate <- IPW_pt["point", 1] - IPW_pt["point", 2]
var_estimate <- sqrt(IPW_pt["variance", 1] + IPW_pt["variance", 2])
# compute the bootstrap sample
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "normalized",
weighting = "cw")
# compute two types of confidence interval
ci_lower_normalized_cw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2)*var_estimate
ci_upper_normalized_cw <- point_estimate - quantile(candidate_sample, sig_level / 2)*var_estimate
# store the intervals
ci_normalized_cw <- c(ci_lower_normalized_cw, ci_upper_normalized_cw)
# compute the bootstrap sample for unnormalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "unnormalized",
weighting = "cw")
# compute normalized ci interval
ci_lower_unnormalized_cw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2) / sqrt(n*2)
ci_upper_unnormalized_cw <- point_estimate - quantile(candidate_sample, sig_level / 2) / sqrt(n*2)
# store the intervals
ci_unnormalized_cw <- c(ci_lower_unnormalized_cw, ci_upper_unnormalized_cw)
################################################################################
# store the rejection rate
result_mat_bootstrap[cumulative_realization + 1, "naive", as.character(signal)] <- dplyr::if_else(all(0 > ci_naive[1],
0 < ci_naive[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "normalized_aw", as.character(signal)] <- dplyr::if_else(all(0 > ci_normalized_aw[1],
0 < ci_normalized_aw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "normalized_cw", as.character(signal)] <- dplyr::if_else(all(0 > ci_normalized_cw[1],
0 < ci_normalized_cw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "unnormalized_aw", as.character(signal)] <- dplyr::if_else(all(0 > ci_unnormalized_aw[1],
0 < ci_unnormalized_aw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "unnormalized_cw", as.character(signal)] <- dplyr::if_else(all(0 > ci_unnormalized_cw[1],
0 < ci_unnormalized_cw[2]),
0, 1)
# print the result
print(apply(as.matrix(result_mat_bootstrap[1:(cumulative_realization + 1), , as.character(signal)]), 2, mean))
# add the loop iteration
cumulative_realization <- cumulative_realization + 1
print(cumulative_realization)
}
}
# create the results folder
results_dir <- "overview/results"
if (!dir.exists(results_dir)) {
dir.create(results_dir)
cat("Directory created:", results_dir, "\n")
} else {
cat("Directory already exists:", results_dir, "\n")
}
data_to_save <- as_tibble(as.table(result_mat_bootstrap)) |>
rename(rejection = n) |>
mutate(signal = as.numeric(signal))
# save the result
saveRDS(data_to_save, sprintf("%s/greedy_%d.rds", results_dir, eps*100))
# This is a file demonstrating the usage of the functions in AdaReg package
library(AdaReg)
library(ggplot2)
library(dplyr)
# compare two methods
set.seed(1)
B_rep <- 500
# parameter in epsilon-greedy algorithm
eps <- 0.4
# distribution family
dist_fam <- c("gaussian")
# number of sample, dimension of covariate, number of active covariate
n <- 350
p <- 2
# initial sampling probability
initial_prob <- c(0.5, 0.5)
# specify the coefficient
coef_list <- list(
beta_1 <- numeric(p),
beta_2 <- numeric(p)
)
# significance level
sig_level <- 0.1
signal_level <- seq(0, 0.5, length.out = 5)
# method_list and construct the empty matrix
methods <- c("naive", "normalized_aw",
"normalized_cw",
"unnormalized_aw",
"unnormalized_cw")
# create empty array
result_mat_bootstrap <- array(
data = NA,
dim = c(B_rep, length(methods), length(signal_level)),
dimnames =  list(realization = 1:B_rep,
method = methods,
signal = signal_level)
)
for (signal in signal_level) {
true_mean <- c(0, signal)
# true mean vector
dist_params <- data.frame(
mu = true_mean,
sd = c(1, 2)
)
cumulative_realization <- 0
while (cumulative_realization < B_rep) {
# generate data
data <- data_generate_online(eps = eps, dist_fam = dist_fam, n = n, p = p, coef_list = coef_list, deciding_scheme = "IPW",
dist_params = dist_params, initial_prob = initial_prob, reg_type = reg_type,
hyperparams = hyperparams)
num_arm_second_batch <- length(unique(data$arm[which(data$batch_id == 2)]))
if(num_arm_second_batch == 1){
next
}
################################################################################
# naive estimator
IPW_pt <- IPW(data, first_batch = TRUE)
point_estimate <- IPW_pt$IPW_mean[1] - IPW_pt$IPW_mean[2]
sd_estimate <- sqrt(IPW_pt$IPW_variance[1] + IPW_pt$IPW_variance[2])
# compute normalized ci interval
ci_lower_naive <- point_estimate - qnorm(1 - sig_level / 2)*sd_estimate / sqrt(n / 2)
ci_upper_naive <- point_estimate - qnorm(sig_level / 2)*sd_estimate / sqrt(n / 2)
# store the intervals
ci_naive <- c(ci_lower_naive, ci_upper_naive)
################################################################################
# adaptive weighting
# weighted test statistic
IPW_pt <- weighted_IPW(data)
data_trans <- data
data_trans$reward <- data_trans$reward^2
IPW_sq <- weighted_IPW(data_trans)
variance_Y <- c(IPW_sq["point", 1] - IPW_pt["point", 1]^2,
IPW_sq["point", 2] - IPW_pt["point", 2]^2)
if(any(variance_Y <= 0)){
next
}
point_estimate <- IPW_pt["point", 1] - IPW_pt["point", 2]
var_estimate <- sqrt(IPW_pt["variance", 1] + IPW_pt["variance", 2])
# compute the bootstrap sample for normalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "normalized",
weighting = "aw")
# compute normalized ci interval
ci_lower_normalized_aw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2)*var_estimate
ci_upper_normalized_aw <- point_estimate - quantile(candidate_sample, sig_level / 2)*var_estimate
# store the intervals
ci_normalized_aw <- c(ci_lower_normalized_aw, ci_upper_normalized_aw)
# compute the bootstrap sample for unnormalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "unnormalized",
weighting = "aw")
# compute normalized ci interval
ci_lower_unnormalized_aw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2) / sqrt(n / 2)
ci_upper_unnormalized_aw <- point_estimate - quantile(candidate_sample, sig_level / 2) / sqrt(n / 2)
# store the intervals
ci_unnormalized_aw <- c(ci_lower_unnormalized_aw, ci_upper_unnormalized_aw)
################################################################################
# constant weighting
# unweighted test statistic
IPW_pt <- IPW_pt(data)
data_trans <- data
data_trans$reward <- data_trans$reward^2
IPW_sq <- weighted_IPW(data_trans)
variance_Y <- c(IPW_sq["point", 1] - IPW_pt["point", 1]^2,
IPW_sq["point", 2] - IPW_pt["point", 2]^2)
if(any(variance_Y <= 0)){
next
}
point_estimate <- IPW_pt["point", 1] - IPW_pt["point", 2]
var_estimate <- sqrt(IPW_pt["variance", 1] + IPW_pt["variance", 2])
# compute the bootstrap sample
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "normalized",
weighting = "cw")
# compute two types of confidence interval
ci_lower_normalized_cw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2)*var_estimate
ci_upper_normalized_cw <- point_estimate - quantile(candidate_sample, sig_level / 2)*var_estimate
# store the intervals
ci_normalized_cw <- c(ci_lower_normalized_cw, ci_upper_normalized_cw)
# compute the bootstrap sample for unnormalized test statistic
candidate_sample <- plugin_bootstrap(mean_estimate = IPW_pt["point", ],
variance_estimate = variance_Y,
eps = eps, fs_p = initial_prob[1], normalization = "unnormalized",
weighting = "cw")
# compute normalized ci interval
ci_lower_unnormalized_cw <- point_estimate - quantile(candidate_sample, 1 - sig_level / 2) / sqrt(n*2)
ci_upper_unnormalized_cw <- point_estimate - quantile(candidate_sample, sig_level / 2) / sqrt(n*2)
# store the intervals
ci_unnormalized_cw <- c(ci_lower_unnormalized_cw, ci_upper_unnormalized_cw)
################################################################################
# store the rejection rate
result_mat_bootstrap[cumulative_realization + 1, "naive", as.character(signal)] <- dplyr::if_else(all(0 > ci_naive[1],
0 < ci_naive[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "normalized_aw", as.character(signal)] <- dplyr::if_else(all(0 > ci_normalized_aw[1],
0 < ci_normalized_aw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "normalized_cw", as.character(signal)] <- dplyr::if_else(all(0 > ci_normalized_cw[1],
0 < ci_normalized_cw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "unnormalized_aw", as.character(signal)] <- dplyr::if_else(all(0 > ci_unnormalized_aw[1],
0 < ci_unnormalized_aw[2]),
0, 1)
result_mat_bootstrap[cumulative_realization + 1, "unnormalized_cw", as.character(signal)] <- dplyr::if_else(all(0 > ci_unnormalized_cw[1],
0 < ci_unnormalized_cw[2]),
0, 1)
# print the result
print(apply(as.matrix(result_mat_bootstrap[1:(cumulative_realization + 1), , as.character(signal)]), 2, mean))
# add the loop iteration
cumulative_realization <- cumulative_realization + 1
print(cumulative_realization)
}
}
# create the results folder
results_dir <- "overview/results"
if (!dir.exists(results_dir)) {
dir.create(results_dir)
cat("Directory created:", results_dir, "\n")
} else {
cat("Directory already exists:", results_dir, "\n")
}
data_to_save <- as_tibble(as.table(result_mat_bootstrap)) |>
rename(rejection = n) |>
mutate(signal = as.numeric(signal))
# save the result
saveRDS(data_to_save, sprintf("%s/greedy_%d.rds", results_dir, eps*100))
library(NNCDT)
library(LaplacesDemon)
library(dplyr)
library(MCMCpack)
remove.packages("NNCDT")
setwd("~/Dropbox (Penn)/Graph Based Calibration Test")
install.packages("NNCDT", repos = NULL, type = "source")
