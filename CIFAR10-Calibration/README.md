# Validation of Calibration of CNN using CIFAR-10

This folder contains the necessary files for running a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset, validate the calibration of the model's predictions using an ECMMD-based test, compute Expected Calibration Error (ECE) values, and plot reliability diagrams. The CNN architecture used in this experiment is described in our article [A Kernel-Based Conditional Two-Sample Test Using Nearest Neighbors](https://arxiv.org/abs/2407.16550).

## Folder Contents

- **CIFAR10_Classification.ipynb**: The Jupyter notebook that contains the code for training the CNN on the CIFAR-10 dataset. This notebook also performs the prediction on the test set and outputs the prediction probabilities.
- **Predictions_TestLabels**: A folder containing the true labels and the prediction probabilities generated by the CNN for the CIFAR-10 test set.
  - **test_labels_xy.csv**: A CSV file containing the true labels of the pairs $(x, y)$ of the CIFAR-10 test set.
  - **predictions_xy.csv**: A CSV file containing the prediction probabilities for each test image for the pairs $(x,y)$, as predicted by the CNN.
- **ECMMD.R**: An R script with functions for computing the ECMMD test statistic and the estimated variance for the asymptotic test.
- **AuxillaryFunctions.R**: An auxiliary R script that provides helper functions required to run the ECMMD-based test, compute ECE values, recalibrate using isotonic regression and plot the reliability diagram.
- **Test_and_ECE.R**: An R script that implements the ECMMD-based test for validating the calibration of the model's predictions, computes the ECE values, and stores all results.
- **Reliability_Plot.R**: An R script that plots the reliability diagram based on the prediction probabilities and true labels.
- **Results**: A folder where the results of the ECMMD-based test and the ECE values are stored.
- **Figures**: A folder containing the reliability diagrams and tables with the proportion of rejections from the ECMMD experiment.
  - **x_ymiscalibration.pdf**: `.pdf` files of the reliability diagrams generated for the classes $(x,y)$.
  - **x_y_result.tex**: A `.tex` file containing the tables with the proportion of rejections observed during the ECMMD experiments.

## How to Use

### Running the Notebook

1. **Open `CIFAR10_Classification.ipynb`**:
   - Open the notebook in [Google Colab](https://colab.research.google.com/), a local Jupyter environment, or any compatible environment.

2. **Execute the Cells**:
   - Run the cells in the notebook sequentially to train the CNN on the CIFAR-10 training dataset.
   - The notebook will load the CIFAR-10 dataset, define the CNN architecture (as described in the referenced paper), train the model, and evaluate it on the test set.

3. **Outputs**:
   - The notebook outputs the following files, stored in the `Predictions_TestLables` folder:
     - **test_labels_xy.csv**: Contains the true labels of the CIFAR-10 test set in the class $(x,y)$ classification task.
     - **predictions_xy.csv**: Contains the prediction probabilities for each $(x,y)$ class test image in CIFAR-10 .

### Running the ECMMD-Based Test for Calibration Validation and ECE Calculation

1. **Open `Test_and_ECE.R`**:
   - Open the R script in an R environment, such as RStudio.
  
2. **Dependencies**:
   - The R script `Test_and_ECE.R` loads the helper functions provided in `ECMMD.R` and `AuxillaryFunctions.R`. These helper scripts should be located in the same directory as `Test_and_ECE.R`.

2. **Run the Script**:
   - Execute the `Test_and_ECE.R` script to perform the ECMMD-based test on validating the calibration of the CNN before and after re-calibration using isotonic regression and compute the Expected Calibration Error (ECE) values. 

3. **Results**:
   - The proportion of rejection using the ECMMD-based test and the ECE values, are stored in the `Results` folder.

### Plotting the Reliability Diagram

1. **Open `Reliability_Plot.R`**:
   - Open this script in an R environment.

2. **Dependencies**:
   - The R script `Reliability_Plot.R` loads helper function from `AuxillaryFunctions.R`. This helper script should be located in the same directory as the `Reliability_Plot.R` script.

2. **Run the Script**:
   - The script reads the `test_labels_xy.csv` and `predictions_xy.csv` files from the `Predictions_TestLabels` folder and generates a reliability diagram before and after recalibration using isotonic regression. The reliability diagram visually represents the calibration of the model's predictions by comparing predicted probabilities to observed frequencies.

3. **Review the Diagram**:
   - The reliability diagrams generated will be saved in the `Figures` folder, with file names indicating the corresponding pair of classes.
   
### Analyzing the Results

- **Review Reliability Diagrams**:
  - The `Figures` folder contains the reliability diagrams generated by the script for different pair of classes. These diagrams help assess how well-calibrated the CNN's predictions are before and after re-calibration.

- **Proportion of Rejections**:
  - The `Figures` folder also contains `.tex` files `x_y_result.tex`, which details the proportion of rejections observed during the ECMMD experiments. This table provides insight towards validating calibration of CNN before and after re-calibration.

### Model Architecture

The CNN architecture used in this experiment follows the design described in [Paper Title/Reference]. The architecture includes three convolutional layers interspersed with max-pooling layers. Post convolution a flattening transformation is used followed by a fully connected layer. For binary classification the output layer uses a softmax activation function.

## Notes

- The notebook is designed to be run in a Python environment with TensorFlow.
- Ensure that all required packages are installed in your environment before running the notebook. The necessary packages are listed at the beginning of the notebook.
- The CIFAR-10 dataset is automatically downloaded from the official source if it is not already available in the environment.
- The R scripts should be run in an environment where all necessary R packages are installed. These packages will be listed at the beginning of the scripts.
- The `Predictions_TestLabels` folder contains the CSV files with the true labels and prediction probabilities, which are used for further analysis, calibration validation, and plotting the reliability diagram.
- The `Results` folder stores the outputs of the ECMMD-based test and the computed ECE values.
- The `Figures` folder contains the reliability diagrams and tables summarizing the proportion of rejections, which provide additional insights into the model's calibration performance.

## References

- [Paper Title/Reference]: A detailed description of the CNN architecture used in this experiment.
- ECMMD-based Test: The proposed test for validating the calibration of probabilistic models.
- Expected Calibration Error (ECE): A metric used to quantify the calibration of probabilistic predictions.
- Reliability Diagram: A visual tool for assessing the calibration of probabilistic predictions.

## License

This experiment and all related files are licensed under the same terms as the main repository. See the [LICENSE](../LICENSE) file for details.
